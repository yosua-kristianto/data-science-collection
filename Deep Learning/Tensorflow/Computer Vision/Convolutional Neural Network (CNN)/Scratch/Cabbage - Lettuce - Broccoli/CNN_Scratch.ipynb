{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRhEbaQGUzdT"
      },
      "source": [
        "# Image Classification from Scratch\n",
        "\n",
        "This book contains image classification from scratch leveraging the superiority of Convolutional Neural Network (CNN).\n",
        "\n",
        "The dataset is based on ['Vegetable Image Dataset'](https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset).\n",
        "\n",
        "Ahmed, M. Israk & Mamun, Shahriyar & Asif, Asif. (2021). DCNN-Based Vegetable Image Classification Using Transfer Learning: A Comparative Study. 235-243. 10.1109/ICCCSP52374.2021.9465499."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzWO0TdzVFHY",
        "outputId": "6b2d20d7-0a88-4749-ca2e-47e4b145bd1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pillow tensorflow numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8jgJJR4AT6tK"
      },
      "outputs": [],
      "source": [
        "import requests;\n",
        "import time;\n",
        "from pathlib import Path;\n",
        "import os;\n",
        "import numpy;\n",
        "\n",
        "import tensorflow;\n",
        "from tensorflow.keras.models import Sequential;\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout;\n",
        "\n",
        "from PIL import Image;\n",
        "from numpy import asarray;\n",
        "\n",
        "import matplotlib.pyplot as plt;\n",
        "\n",
        "from tensorflow.keras.utils import plot_model;\n",
        "from tensorflow.keras.callbacks import EarlyStopping;\n",
        "\n",
        "from tensorflow.keras.regularizers import l2, l1_l2;\n",
        "\n",
        "from google.colab import drive;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhBlKyE_UFrY",
        "outputId": "e1e327cf-5ec7-47cc-c79e-e961b1b6dd92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Check whether the GPU is exist\n",
        "tensorflow.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l2ISIEzZUST6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988d7779-81ed-44ff-90aa-47e95896538b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Directory configuration\n",
        "drive.mount('/content/drive');\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/Collab Dataset/Vegetable Images\";\n",
        "train_path = base_path + \"/train\";\n",
        "test_path = base_path + \"/test\";\n",
        "val_path = base_path + \"/validation\";"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7T2NzXLyGGE"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBHPNLVszxvz"
      },
      "source": [
        "## Dataset Pre-Processing\n",
        "\n",
        "Regarding the nature of the data with structures as below:\n",
        "\n",
        "```\n",
        "Vegetable Images\n",
        "|- validation\n",
        "  |- label1\n",
        "    |- image1\n",
        "    |- imagen\n",
        "  |- labeln\n",
        "|- train\n",
        "|- test\n",
        "```\n",
        "\n",
        "Therefore, the pre-processing leveraging the folder structure is needed by applying algorithm below:\n",
        "\n",
        "```\n",
        "dataset = [feature_train = [], feature_test = [], feature_val = []]\n",
        "labels = [label_train = [], label_test = [], label_val = []]\n",
        "\n",
        "FOR idx, everything IN ENUMERATE([train, test, validation])\n",
        "  FOR folder IN everything\n",
        "    SET label = folder.name\n",
        "    \n",
        "    FOR file IN folder\n",
        "      APPEND dataset[idx], CONVERT_FILE_TO_ARRAY(file)\n",
        "      APPEND labels[idx], label\n",
        "```\n",
        "\n",
        "Basically:\n",
        "\n",
        "1. Convert the dataset from image format into float array format.\n",
        "2. Make enumeration from the label dataset since Tensorflow only can retrieve \"Tensor\". The rule below are applied:\n",
        "> 1: Brocolli\n",
        "> 2: Cabbage\n",
        "> 3: Cauliflower\n",
        "3. Save the converted dataset to the float array of `dataset_feature`.\n",
        "4. Set the folder name as its data label of the converted feature.\n",
        "5. Save the label to `dataset_label`.\n",
        "6. Perform OneHotEncoding to all dataset_label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CP4rLgllyFkt"
      },
      "outputs": [],
      "source": [
        "dataset_feature = [\n",
        "    [], # Train\n",
        "    [], # Test\n",
        "    []  # Val\n",
        "];\n",
        "\n",
        "dataset_label = [\n",
        "    [], # Train\n",
        "    [], # Test\n",
        "    []  # Val\n",
        "];\n",
        "\n",
        "for idx, e in enumerate([train_path, test_path, val_path]):\n",
        "  folders = Path(e).glob(\"*\");\n",
        "\n",
        "  # Navigate to folder\n",
        "  for folder in folders:\n",
        "    folder_name = os.path.basename(folder);\n",
        "    if(folder_name in [\"Broccoli\", \"Cabbage\", \"Cauliflower\"]):\n",
        "      label = 0;\n",
        "      match(folder_name):\n",
        "        case \"Broccoli\":\n",
        "          label = 0;\n",
        "\n",
        "        case \"Cabbage\":\n",
        "          label = 1;\n",
        "\n",
        "        case \"Cauliflower\":\n",
        "          label = 2;\n",
        "\n",
        "\n",
        "      # Get all files by navigating to folder\n",
        "      files = Path(folder).glob(\"*\");\n",
        "\n",
        "      # Mapping and convert features with the corresponding label\n",
        "      for file in files:\n",
        "        image = Image.open(Path(file));\n",
        "\n",
        "        # Convert feature from image to tensor\n",
        "        converted_tensor_from_image = asarray(image);\n",
        "        converted_tensor_from_image = converted_tensor_from_image / 255.0;\n",
        "\n",
        "        # Load the dataset to the list\n",
        "        dataset_feature[idx].append(converted_tensor_from_image);\n",
        "        dataset_label[idx].append(label);\n",
        "\n",
        "  # Perform One-Hot Encoding for the dataset_label\n",
        "  dataset_label[idx] = tensorflow.one_hot(dataset_label[idx], depth = 3);\n",
        "\n",
        "train_images = dataset_feature[0];\n",
        "test_images = dataset_feature[1];\n",
        "val_images = dataset_feature[2];\n",
        "train_labels = dataset_label[0];\n",
        "test_labels = dataset_label[1];\n",
        "val_labels = dataset_label[2];"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xkprlT-ddXm"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "This exploration endavour taking feature data shape to make an exact model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5FM0kcnnd-n6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16489da2-1ac4-4679-8047-0d533a6ae19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset shape: \n",
            "Total dataset, width, height\n",
            "3000 224 224\n",
            "3000 3\n",
            "600 224 224\n",
            "600 3\n",
            "600 224 224\n",
            "600 3\n"
          ]
        }
      ],
      "source": [
        "print(\"Training dataset shape: \")\n",
        "\n",
        "print(\"Total dataset, width, height\")\n",
        "\n",
        "print(len(train_images), len(train_images[0]), len(train_images[0][0]))\n",
        "print(len(train_labels), len(train_labels[0]));\n",
        "\n",
        "print(len(test_images), len(test_images[0]), len(test_images[0][0]))\n",
        "print(len(test_labels), len(test_labels[0]));\n",
        "\n",
        "print(len(val_images), len(val_images[0]), len(val_images[0][0]))\n",
        "print(len(val_labels), len(val_labels[0]));\n",
        "\n",
        "train_images = numpy.array(train_images);\n",
        "test_images = numpy.array(test_images);\n",
        "val_images = numpy.array(val_images);\n",
        "train_labels = numpy.array(train_labels);\n",
        "test_labels = numpy.array(test_labels);\n",
        "val_labels = numpy.array(val_labels);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuiscaBcVo5w"
      },
      "source": [
        "## Support Functions\n",
        "\n",
        "### 1. Telegram Reporter\n",
        "\n",
        "This notebook filled with helper to report whether training is started or stopped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QgQ-7PMKV4NV"
      },
      "outputs": [],
      "source": [
        "# telegram_reporter\n",
        "\"\"\"\n",
        "This function helps to send message to telegram private channel\n",
        "\"\"\"\n",
        "def telegram_reporter(message):\n",
        "    message = \"[\" + time.strftime(\"%Y-%m-%d %H:%M:%S\") +\"][CNN FROM SCRATCH] \" + message\n",
        "    requests.request(\n",
        "        method=\"POST\",\n",
        "        url=\"https://api.telegram.org/bot6307342709:AAEehfQrvZzQhk2hFlOW7C1JnE2hRQYLEgE/sendMessage?chat_id=-1001525528850&text=\" + message,\n",
        "        headers={},\n",
        "        data={}\n",
        "    );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF-LoMzbdUdE"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FHPa6uPH9RPn"
      },
      "outputs": [],
      "source": [
        "class CNNModel:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.input = Input(shape = (224, 224, 3));\n",
        "    self.conv1 = Conv2D(filters = 64, kernel_size = (3, 3), activation = \"leaky_relu\");\n",
        "    self.pool1 = MaxPooling2D((2, 2));\n",
        "\n",
        "    self.conv2 = Conv2D(filters = 128, kernel_size = (5, 5), activation = \"leaky_relu\");\n",
        "    self.pool2 = MaxPooling2D((2, 2));\n",
        "\n",
        "    self.conv3 = Conv2D(filters = 64, kernel_size = (3, 3), activation = \"leaky_relu\");\n",
        "    self.pool3 = MaxPooling2D((3, 3));\n",
        "\n",
        "    self.conv4 = Conv2D(filters = 32, kernel_size = (1, 1), activation = \"leaky_relu\");\n",
        "    self.pool4 = MaxPooling2D((3, 3));\n",
        "\n",
        "    self.fullycon = Flatten();\n",
        "    self.do1 = Dropout(0.5);\n",
        "    self.dense = Dense(128, activation = \"relu\");\n",
        "    self.output = Dense(3, activation = \"softmax\");\n",
        "\n",
        "  # Early stopping after loss are not improved for some epochs\n",
        "  def _callback_early_stopping(self):\n",
        "      early_stopping_tolerance = 50;\n",
        "      return EarlyStopping(\n",
        "          monitor = \"val_loss\",\n",
        "          patience = early_stopping_tolerance,\n",
        "          restore_best_weights = True\n",
        "      );\n",
        "\n",
        "  def fitting(self):\n",
        "    model = Sequential();\n",
        "\n",
        "    model.add(self.input);\n",
        "    model.add(self.conv1);\n",
        "    model.add(self.pool1);\n",
        "\n",
        "    model.add(self.conv2);\n",
        "    model.add(self.pool2);\n",
        "\n",
        "    model.add(self.conv3);\n",
        "    model.add(self.pool3);\n",
        "\n",
        "    model.add(self.conv4);\n",
        "    model.add(self.pool4);\n",
        "\n",
        "    model.add(self.fullycon);\n",
        "    model.add(self.do1);\n",
        "    model.add(self.dense);\n",
        "    model.add(self.output);\n",
        "\n",
        "    model.compile(optimizer = \"sgd\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"]);\n",
        "    model.summary();\n",
        "\n",
        "    plot_model(model, to_file = (\"model_architecture.png\"), show_shapes = True);\n",
        "\n",
        "\n",
        "    history = model.fit(\n",
        "        train_images,\n",
        "        train_labels,\n",
        "        epochs = 300,\n",
        "        batch_size = 64,\n",
        "        validation_data = (val_images, val_labels),\n",
        "        callbacks = [self._callback_early_stopping()]\n",
        "    );\n",
        "\n",
        "    # Plot training history\n",
        "    plt.plot(history.history['loss'], label='Training Loss');\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss');\n",
        "    plt.xlabel('Epoch');\n",
        "    plt.ylabel('Loss');\n",
        "    plt.legend();\n",
        "    plt.show();\n",
        "\n",
        "    return model;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RSI4aMvn-RSx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c957962b-e723-44dd-9166-e28d05a266dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 222, 222, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 111, 111, 64)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 107, 107, 128)     204928    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 53, 53, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 51, 51, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 17, 17, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 17, 17, 32)        2080      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 5, 5, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 800)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               102528    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 385507 (1.47 MB)\n",
            "Trainable params: 385507 (1.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "47/47 [==============================] - 9s 172ms/step - loss: 1.1001 - accuracy: 0.3440 - val_loss: 1.0934 - val_accuracy: 0.3300\n",
            "Epoch 2/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 1.0912 - accuracy: 0.3870 - val_loss: 1.0860 - val_accuracy: 0.3617\n",
            "Epoch 3/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 1.0834 - accuracy: 0.4160 - val_loss: 1.0753 - val_accuracy: 0.5800\n",
            "Epoch 4/300\n",
            "47/47 [==============================] - 7s 156ms/step - loss: 1.0744 - accuracy: 0.4540 - val_loss: 1.0599 - val_accuracy: 0.6217\n",
            "Epoch 5/300\n",
            "47/47 [==============================] - 7s 156ms/step - loss: 1.0549 - accuracy: 0.5073 - val_loss: 1.0283 - val_accuracy: 0.6333\n",
            "Epoch 6/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 1.0175 - accuracy: 0.5480 - val_loss: 0.9613 - val_accuracy: 0.5983\n",
            "Epoch 7/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.9536 - accuracy: 0.5843 - val_loss: 0.9842 - val_accuracy: 0.4750\n",
            "Epoch 8/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.9178 - accuracy: 0.5553 - val_loss: 0.8051 - val_accuracy: 0.6933\n",
            "Epoch 9/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.8354 - accuracy: 0.6290 - val_loss: 0.7222 - val_accuracy: 0.6950\n",
            "Epoch 10/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.7881 - accuracy: 0.6517 - val_loss: 0.6339 - val_accuracy: 0.6933\n",
            "Epoch 11/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.7280 - accuracy: 0.6783 - val_loss: 0.5555 - val_accuracy: 0.7983\n",
            "Epoch 12/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.7024 - accuracy: 0.7047 - val_loss: 0.8384 - val_accuracy: 0.5050\n",
            "Epoch 13/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.6515 - accuracy: 0.7407 - val_loss: 0.5264 - val_accuracy: 0.7950\n",
            "Epoch 14/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.6166 - accuracy: 0.7517 - val_loss: 0.4692 - val_accuracy: 0.8367\n",
            "Epoch 15/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.6516 - accuracy: 0.7330 - val_loss: 0.6577 - val_accuracy: 0.7600\n",
            "Epoch 16/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.5701 - accuracy: 0.7863 - val_loss: 0.4204 - val_accuracy: 0.8567\n",
            "Epoch 17/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.5312 - accuracy: 0.7853 - val_loss: 0.3895 - val_accuracy: 0.8833\n",
            "Epoch 18/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.5132 - accuracy: 0.8033 - val_loss: 0.4605 - val_accuracy: 0.8517\n",
            "Epoch 19/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.4651 - accuracy: 0.8197 - val_loss: 0.4040 - val_accuracy: 0.8417\n",
            "Epoch 20/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.4420 - accuracy: 0.8257 - val_loss: 0.3238 - val_accuracy: 0.8983\n",
            "Epoch 21/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.4472 - accuracy: 0.8247 - val_loss: 0.3227 - val_accuracy: 0.9000\n",
            "Epoch 22/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.4485 - accuracy: 0.8247 - val_loss: 0.2991 - val_accuracy: 0.8967\n",
            "Epoch 23/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.4684 - accuracy: 0.8230 - val_loss: 0.3222 - val_accuracy: 0.8983\n",
            "Epoch 24/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.3721 - accuracy: 0.8613 - val_loss: 0.3483 - val_accuracy: 0.8417\n",
            "Epoch 25/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.3647 - accuracy: 0.8573 - val_loss: 0.3534 - val_accuracy: 0.8833\n",
            "Epoch 26/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.3943 - accuracy: 0.8463 - val_loss: 0.2645 - val_accuracy: 0.9133\n",
            "Epoch 27/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.3293 - accuracy: 0.8783 - val_loss: 0.3640 - val_accuracy: 0.8483\n",
            "Epoch 28/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.3437 - accuracy: 0.8647 - val_loss: 0.4855 - val_accuracy: 0.8117\n",
            "Epoch 29/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.3155 - accuracy: 0.8830 - val_loss: 0.2877 - val_accuracy: 0.8817\n",
            "Epoch 30/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.3303 - accuracy: 0.8787 - val_loss: 0.2599 - val_accuracy: 0.9000\n",
            "Epoch 31/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.2947 - accuracy: 0.8937 - val_loss: 0.2175 - val_accuracy: 0.9300\n",
            "Epoch 32/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.3373 - accuracy: 0.8707 - val_loss: 0.2218 - val_accuracy: 0.9350\n",
            "Epoch 33/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.2854 - accuracy: 0.8917 - val_loss: 0.2159 - val_accuracy: 0.9283\n",
            "Epoch 34/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.2685 - accuracy: 0.9027 - val_loss: 0.2170 - val_accuracy: 0.9133\n",
            "Epoch 35/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.2685 - accuracy: 0.9013 - val_loss: 0.1799 - val_accuracy: 0.9450\n",
            "Epoch 36/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.2498 - accuracy: 0.9020 - val_loss: 0.1925 - val_accuracy: 0.9250\n",
            "Epoch 37/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.2482 - accuracy: 0.9080 - val_loss: 0.1760 - val_accuracy: 0.9533\n",
            "Epoch 38/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.2472 - accuracy: 0.9097 - val_loss: 0.2361 - val_accuracy: 0.9150\n",
            "Epoch 39/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.2291 - accuracy: 0.9193 - val_loss: 0.3419 - val_accuracy: 0.8833\n",
            "Epoch 40/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.2460 - accuracy: 0.9083 - val_loss: 0.1649 - val_accuracy: 0.9433\n",
            "Epoch 41/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.2035 - accuracy: 0.9297 - val_loss: 0.1566 - val_accuracy: 0.9567\n",
            "Epoch 42/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.2339 - accuracy: 0.9130 - val_loss: 0.1778 - val_accuracy: 0.9367\n",
            "Epoch 43/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.2630 - accuracy: 0.9037 - val_loss: 0.1698 - val_accuracy: 0.9417\n",
            "Epoch 44/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.2258 - accuracy: 0.9190 - val_loss: 0.1434 - val_accuracy: 0.9583\n",
            "Epoch 45/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1804 - accuracy: 0.9380 - val_loss: 0.1514 - val_accuracy: 0.9567\n",
            "Epoch 46/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1940 - accuracy: 0.9320 - val_loss: 0.1570 - val_accuracy: 0.9450\n",
            "Epoch 47/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.2049 - accuracy: 0.9260 - val_loss: 0.1548 - val_accuracy: 0.9483\n",
            "Epoch 48/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.2662 - accuracy: 0.9160 - val_loss: 0.1668 - val_accuracy: 0.9433\n",
            "Epoch 49/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1572 - accuracy: 0.9460 - val_loss: 0.1944 - val_accuracy: 0.9283\n",
            "Epoch 50/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1639 - accuracy: 0.9423 - val_loss: 0.1315 - val_accuracy: 0.9550\n",
            "Epoch 51/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1895 - accuracy: 0.9360 - val_loss: 0.1486 - val_accuracy: 0.9467\n",
            "Epoch 52/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1654 - accuracy: 0.9417 - val_loss: 0.1264 - val_accuracy: 0.9617\n",
            "Epoch 53/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1481 - accuracy: 0.9443 - val_loss: 0.1236 - val_accuracy: 0.9600\n",
            "Epoch 54/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1906 - accuracy: 0.9350 - val_loss: 0.1244 - val_accuracy: 0.9617\n",
            "Epoch 55/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1484 - accuracy: 0.9467 - val_loss: 0.1355 - val_accuracy: 0.9583\n",
            "Epoch 56/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1359 - accuracy: 0.9530 - val_loss: 0.1141 - val_accuracy: 0.9633\n",
            "Epoch 57/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1891 - accuracy: 0.9293 - val_loss: 0.1128 - val_accuracy: 0.9650\n",
            "Epoch 58/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1380 - accuracy: 0.9503 - val_loss: 0.1102 - val_accuracy: 0.9650\n",
            "Epoch 59/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1264 - accuracy: 0.9523 - val_loss: 0.1166 - val_accuracy: 0.9633\n",
            "Epoch 60/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1293 - accuracy: 0.9540 - val_loss: 0.1236 - val_accuracy: 0.9583\n",
            "Epoch 61/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1230 - accuracy: 0.9573 - val_loss: 0.1548 - val_accuracy: 0.9433\n",
            "Epoch 62/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1319 - accuracy: 0.9527 - val_loss: 0.1004 - val_accuracy: 0.9700\n",
            "Epoch 63/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1085 - accuracy: 0.9610 - val_loss: 0.1535 - val_accuracy: 0.9517\n",
            "Epoch 64/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1526 - accuracy: 0.9487 - val_loss: 0.2864 - val_accuracy: 0.8850\n",
            "Epoch 65/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1170 - accuracy: 0.9583 - val_loss: 0.1094 - val_accuracy: 0.9667\n",
            "Epoch 66/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1237 - accuracy: 0.9560 - val_loss: 0.1301 - val_accuracy: 0.9517\n",
            "Epoch 67/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1340 - accuracy: 0.9493 - val_loss: 0.0949 - val_accuracy: 0.9717\n",
            "Epoch 68/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0990 - accuracy: 0.9640 - val_loss: 0.1017 - val_accuracy: 0.9650\n",
            "Epoch 69/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1093 - accuracy: 0.9623 - val_loss: 0.1002 - val_accuracy: 0.9633\n",
            "Epoch 70/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1046 - accuracy: 0.9613 - val_loss: 0.0979 - val_accuracy: 0.9650\n",
            "Epoch 71/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1247 - accuracy: 0.9520 - val_loss: 0.0839 - val_accuracy: 0.9767\n",
            "Epoch 72/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1012 - accuracy: 0.9650 - val_loss: 0.0903 - val_accuracy: 0.9700\n",
            "Epoch 73/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1080 - accuracy: 0.9647 - val_loss: 0.1144 - val_accuracy: 0.9600\n",
            "Epoch 74/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1190 - accuracy: 0.9623 - val_loss: 0.1563 - val_accuracy: 0.9400\n",
            "Epoch 75/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0881 - accuracy: 0.9703 - val_loss: 0.0932 - val_accuracy: 0.9667\n",
            "Epoch 76/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1039 - accuracy: 0.9610 - val_loss: 0.0922 - val_accuracy: 0.9650\n",
            "Epoch 77/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0973 - accuracy: 0.9677 - val_loss: 0.0936 - val_accuracy: 0.9667\n",
            "Epoch 78/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0993 - accuracy: 0.9647 - val_loss: 0.1030 - val_accuracy: 0.9700\n",
            "Epoch 79/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0965 - accuracy: 0.9683 - val_loss: 0.1043 - val_accuracy: 0.9600\n",
            "Epoch 80/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0859 - accuracy: 0.9737 - val_loss: 0.1602 - val_accuracy: 0.9433\n",
            "Epoch 81/300\n",
            "47/47 [==============================] - 7s 156ms/step - loss: 0.0914 - accuracy: 0.9683 - val_loss: 0.0774 - val_accuracy: 0.9733\n",
            "Epoch 82/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0893 - accuracy: 0.9697 - val_loss: 0.0820 - val_accuracy: 0.9683\n",
            "Epoch 83/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.5852 - accuracy: 0.9017 - val_loss: 0.1670 - val_accuracy: 0.9500\n",
            "Epoch 84/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1407 - accuracy: 0.9523 - val_loss: 0.1026 - val_accuracy: 0.9717\n",
            "Epoch 85/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1281 - accuracy: 0.9577 - val_loss: 0.1306 - val_accuracy: 0.9567\n",
            "Epoch 86/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1071 - accuracy: 0.9633 - val_loss: 0.0817 - val_accuracy: 0.9800\n",
            "Epoch 87/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0862 - accuracy: 0.9710 - val_loss: 0.0995 - val_accuracy: 0.9650\n",
            "Epoch 88/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0923 - accuracy: 0.9690 - val_loss: 0.0867 - val_accuracy: 0.9683\n",
            "Epoch 89/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0834 - accuracy: 0.9733 - val_loss: 0.1068 - val_accuracy: 0.9617\n",
            "Epoch 90/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1450 - accuracy: 0.9517 - val_loss: 0.0793 - val_accuracy: 0.9750\n",
            "Epoch 91/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0725 - accuracy: 0.9780 - val_loss: 0.0684 - val_accuracy: 0.9817\n",
            "Epoch 92/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0753 - accuracy: 0.9757 - val_loss: 0.0908 - val_accuracy: 0.9683\n",
            "Epoch 93/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0774 - accuracy: 0.9723 - val_loss: 0.1011 - val_accuracy: 0.9650\n",
            "Epoch 94/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0738 - accuracy: 0.9740 - val_loss: 0.0655 - val_accuracy: 0.9817\n",
            "Epoch 95/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0790 - accuracy: 0.9740 - val_loss: 0.0641 - val_accuracy: 0.9817\n",
            "Epoch 96/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0651 - accuracy: 0.9783 - val_loss: 0.1194 - val_accuracy: 0.9567\n",
            "Epoch 97/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0897 - accuracy: 0.9680 - val_loss: 0.0607 - val_accuracy: 0.9817\n",
            "Epoch 98/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0625 - accuracy: 0.9803 - val_loss: 0.0632 - val_accuracy: 0.9817\n",
            "Epoch 99/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1313 - accuracy: 0.9570 - val_loss: 0.0853 - val_accuracy: 0.9767\n",
            "Epoch 100/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0755 - accuracy: 0.9723 - val_loss: 0.0622 - val_accuracy: 0.9783\n",
            "Epoch 101/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0608 - accuracy: 0.9817 - val_loss: 0.0632 - val_accuracy: 0.9767\n",
            "Epoch 102/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0670 - accuracy: 0.9787 - val_loss: 0.0742 - val_accuracy: 0.9750\n",
            "Epoch 103/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0587 - accuracy: 0.9800 - val_loss: 0.0561 - val_accuracy: 0.9850\n",
            "Epoch 104/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0586 - accuracy: 0.9807 - val_loss: 0.0600 - val_accuracy: 0.9783\n",
            "Epoch 105/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.1788 - val_accuracy: 0.9550\n",
            "Epoch 106/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0826 - accuracy: 0.9690 - val_loss: 0.0818 - val_accuracy: 0.9717\n",
            "Epoch 107/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0673 - accuracy: 0.9757 - val_loss: 0.0657 - val_accuracy: 0.9767\n",
            "Epoch 108/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0598 - accuracy: 0.9827 - val_loss: 0.0548 - val_accuracy: 0.9833\n",
            "Epoch 109/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0664 - accuracy: 0.9763 - val_loss: 0.1717 - val_accuracy: 0.9550\n",
            "Epoch 110/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0530 - accuracy: 0.9833 - val_loss: 0.0556 - val_accuracy: 0.9800\n",
            "Epoch 111/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0561 - accuracy: 0.9810 - val_loss: 0.0626 - val_accuracy: 0.9800\n",
            "Epoch 112/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0548 - accuracy: 0.9817 - val_loss: 0.0741 - val_accuracy: 0.9783\n",
            "Epoch 113/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.0652 - val_accuracy: 0.9767\n",
            "Epoch 114/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0490 - accuracy: 0.9840 - val_loss: 0.0598 - val_accuracy: 0.9767\n",
            "Epoch 115/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0596 - accuracy: 0.9800 - val_loss: 0.0851 - val_accuracy: 0.9683\n",
            "Epoch 116/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0515 - accuracy: 0.9823 - val_loss: 0.0466 - val_accuracy: 0.9850\n",
            "Epoch 117/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0474 - accuracy: 0.9837 - val_loss: 0.0551 - val_accuracy: 0.9817\n",
            "Epoch 118/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0536 - accuracy: 0.9793 - val_loss: 0.0652 - val_accuracy: 0.9800\n",
            "Epoch 119/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0529 - accuracy: 0.9820 - val_loss: 0.0498 - val_accuracy: 0.9817\n",
            "Epoch 120/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0875 - accuracy: 0.9683 - val_loss: 0.0429 - val_accuracy: 0.9850\n",
            "Epoch 121/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0585 - accuracy: 0.9823 - val_loss: 0.0497 - val_accuracy: 0.9833\n",
            "Epoch 122/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 0.0449 - val_accuracy: 0.9833\n",
            "Epoch 123/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0500 - accuracy: 0.9843 - val_loss: 0.0496 - val_accuracy: 0.9833\n",
            "Epoch 124/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0510 - accuracy: 0.9820 - val_loss: 0.0422 - val_accuracy: 0.9867\n",
            "Epoch 125/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0515 - accuracy: 0.9797 - val_loss: 0.0550 - val_accuracy: 0.9850\n",
            "Epoch 126/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 0.0437 - val_accuracy: 0.9883\n",
            "Epoch 127/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0436 - accuracy: 0.9850 - val_loss: 0.0793 - val_accuracy: 0.9700\n",
            "Epoch 128/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0415 - accuracy: 0.9877 - val_loss: 0.0514 - val_accuracy: 0.9850\n",
            "Epoch 129/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0405 - accuracy: 0.9863 - val_loss: 0.0450 - val_accuracy: 0.9850\n",
            "Epoch 130/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0396 - accuracy: 0.9883 - val_loss: 0.0424 - val_accuracy: 0.9817\n",
            "Epoch 131/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.0504 - val_accuracy: 0.9800\n",
            "Epoch 132/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0393 - accuracy: 0.9887 - val_loss: 0.0403 - val_accuracy: 0.9850\n",
            "Epoch 133/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.1097 - accuracy: 0.9710 - val_loss: 0.0509 - val_accuracy: 0.9850\n",
            "Epoch 134/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 0.0537 - val_accuracy: 0.9800\n",
            "Epoch 135/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0455 - accuracy: 0.9837 - val_loss: 0.0531 - val_accuracy: 0.9817\n",
            "Epoch 136/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 0.0471 - val_accuracy: 0.9817\n",
            "Epoch 137/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0429 - accuracy: 0.9847 - val_loss: 0.0561 - val_accuracy: 0.9817\n",
            "Epoch 138/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0386 - accuracy: 0.9880 - val_loss: 0.0755 - val_accuracy: 0.9783\n",
            "Epoch 139/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0374 - accuracy: 0.9870 - val_loss: 0.0414 - val_accuracy: 0.9883\n",
            "Epoch 140/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.0352 - val_accuracy: 0.9883\n",
            "Epoch 141/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 0.0461 - val_accuracy: 0.9833\n",
            "Epoch 142/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0420 - accuracy: 0.9840 - val_loss: 0.0605 - val_accuracy: 0.9833\n",
            "Epoch 143/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0372 - accuracy: 0.9873 - val_loss: 0.0481 - val_accuracy: 0.9833\n",
            "Epoch 144/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0383 - accuracy: 0.9880 - val_loss: 0.0457 - val_accuracy: 0.9800\n",
            "Epoch 145/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0315 - accuracy: 0.9873 - val_loss: 0.0570 - val_accuracy: 0.9767\n",
            "Epoch 146/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0504 - accuracy: 0.9803 - val_loss: 0.0378 - val_accuracy: 0.9883\n",
            "Epoch 147/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0372 - accuracy: 0.9860 - val_loss: 0.0678 - val_accuracy: 0.9717\n",
            "Epoch 148/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0344 - accuracy: 0.9900 - val_loss: 0.0444 - val_accuracy: 0.9850\n",
            "Epoch 149/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0363 - accuracy: 0.9873 - val_loss: 0.0394 - val_accuracy: 0.9867\n",
            "Epoch 150/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.0478 - val_accuracy: 0.9833\n",
            "Epoch 151/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.1014 - accuracy: 0.9643 - val_loss: 0.0423 - val_accuracy: 0.9850\n",
            "Epoch 152/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0407 - accuracy: 0.9850 - val_loss: 0.0340 - val_accuracy: 0.9867\n",
            "Epoch 153/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 0.0374 - val_accuracy: 0.9883\n",
            "Epoch 154/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.0430 - val_accuracy: 0.9867\n",
            "Epoch 155/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0380 - accuracy: 0.9873 - val_loss: 0.0378 - val_accuracy: 0.9867\n",
            "Epoch 156/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0357 - val_accuracy: 0.9883\n",
            "Epoch 157/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0335 - accuracy: 0.9890 - val_loss: 0.0337 - val_accuracy: 0.9883\n",
            "Epoch 158/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0585 - accuracy: 0.9817 - val_loss: 0.0369 - val_accuracy: 0.9850\n",
            "Epoch 159/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: 0.0465 - val_accuracy: 0.9800\n",
            "Epoch 160/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0279 - accuracy: 0.9893 - val_loss: 0.0531 - val_accuracy: 0.9817\n",
            "Epoch 161/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0256 - accuracy: 0.9907 - val_loss: 0.0543 - val_accuracy: 0.9767\n",
            "Epoch 162/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0322 - val_accuracy: 0.9883\n",
            "Epoch 163/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0355 - accuracy: 0.9897 - val_loss: 0.0397 - val_accuracy: 0.9833\n",
            "Epoch 164/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.0336 - val_accuracy: 0.9867\n",
            "Epoch 165/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0562 - accuracy: 0.9800 - val_loss: 0.0340 - val_accuracy: 0.9933\n",
            "Epoch 166/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 0.0352 - val_accuracy: 0.9883\n",
            "Epoch 167/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0273 - accuracy: 0.9907 - val_loss: 0.0329 - val_accuracy: 0.9883\n",
            "Epoch 168/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0245 - accuracy: 0.9943 - val_loss: 0.0366 - val_accuracy: 0.9850\n",
            "Epoch 169/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.0336 - val_accuracy: 0.9900\n",
            "Epoch 170/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0347 - accuracy: 0.9883 - val_loss: 0.0323 - val_accuracy: 0.9883\n",
            "Epoch 171/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0319 - val_accuracy: 0.9900\n",
            "Epoch 172/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.0723 - val_accuracy: 0.9650\n",
            "Epoch 173/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0365 - accuracy: 0.9857 - val_loss: 0.0301 - val_accuracy: 0.9933\n",
            "Epoch 174/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.0359 - val_accuracy: 0.9883\n",
            "Epoch 175/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0335 - accuracy: 0.9883 - val_loss: 0.0332 - val_accuracy: 0.9883\n",
            "Epoch 176/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 0.0381 - val_accuracy: 0.9833\n",
            "Epoch 177/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.0422 - val_accuracy: 0.9817\n",
            "Epoch 178/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
            "Epoch 179/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0322 - val_accuracy: 0.9900\n",
            "Epoch 180/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0612 - val_accuracy: 0.9833\n",
            "Epoch 181/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0392 - val_accuracy: 0.9883\n",
            "Epoch 182/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0258 - accuracy: 0.9907 - val_loss: 0.0318 - val_accuracy: 0.9900\n",
            "Epoch 183/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.0417 - val_accuracy: 0.9850\n",
            "Epoch 184/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0384 - accuracy: 0.9863 - val_loss: 0.0377 - val_accuracy: 0.9867\n",
            "Epoch 185/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.0730 - val_accuracy: 0.9667\n",
            "Epoch 186/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 0.0362 - val_accuracy: 0.9883\n",
            "Epoch 187/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0236 - accuracy: 0.9907 - val_loss: 0.0350 - val_accuracy: 0.9900\n",
            "Epoch 188/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0234 - accuracy: 0.9910 - val_loss: 0.0342 - val_accuracy: 0.9900\n",
            "Epoch 189/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.0353 - val_accuracy: 0.9883\n",
            "Epoch 190/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0260 - accuracy: 0.9900 - val_loss: 0.0992 - val_accuracy: 0.9700\n",
            "Epoch 191/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0415 - val_accuracy: 0.9900\n",
            "Epoch 192/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0268 - val_accuracy: 0.9917\n",
            "Epoch 193/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0255 - accuracy: 0.9903 - val_loss: 0.0494 - val_accuracy: 0.9867\n",
            "Epoch 194/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.0349 - val_accuracy: 0.9900\n",
            "Epoch 195/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.0259 - val_accuracy: 0.9883\n",
            "Epoch 196/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0293 - val_accuracy: 0.9883\n",
            "Epoch 197/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.0332 - val_accuracy: 0.9917\n",
            "Epoch 198/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 0.0284 - val_accuracy: 0.9900\n",
            "Epoch 199/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.1132 - val_accuracy: 0.9617\n",
            "Epoch 200/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0230 - accuracy: 0.9910 - val_loss: 0.0344 - val_accuracy: 0.9917\n",
            "Epoch 201/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0400 - val_accuracy: 0.9850\n",
            "Epoch 202/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0223 - accuracy: 0.9910 - val_loss: 0.0304 - val_accuracy: 0.9917\n",
            "Epoch 203/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.0323 - val_accuracy: 0.9933\n",
            "Epoch 204/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 0.0401 - val_accuracy: 0.9900\n",
            "Epoch 205/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0155 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9933\n",
            "Epoch 206/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0215 - accuracy: 0.9913 - val_loss: 0.0618 - val_accuracy: 0.9783\n",
            "Epoch 207/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0252 - accuracy: 0.9900 - val_loss: 0.0444 - val_accuracy: 0.9850\n",
            "Epoch 208/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.0259 - val_accuracy: 0.9917\n",
            "Epoch 209/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0187 - accuracy: 0.9923 - val_loss: 0.0292 - val_accuracy: 0.9933\n",
            "Epoch 210/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.0271 - val_accuracy: 0.9900\n",
            "Epoch 211/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0262 - accuracy: 0.9883 - val_loss: 0.0254 - val_accuracy: 0.9933\n",
            "Epoch 212/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.0287 - val_accuracy: 0.9917\n",
            "Epoch 213/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.0243 - val_accuracy: 0.9933\n",
            "Epoch 214/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.0308 - val_accuracy: 0.9900\n",
            "Epoch 215/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 0.0366 - val_accuracy: 0.9900\n",
            "Epoch 216/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.0250 - val_accuracy: 0.9933\n",
            "Epoch 217/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0267 - val_accuracy: 0.9933\n",
            "Epoch 218/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0146 - accuracy: 0.9943 - val_loss: 0.0285 - val_accuracy: 0.9900\n",
            "Epoch 219/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.0274 - val_accuracy: 0.9917\n",
            "Epoch 220/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.0304 - val_accuracy: 0.9933\n",
            "Epoch 221/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.0250 - val_accuracy: 0.9917\n",
            "Epoch 222/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0257 - val_accuracy: 0.9917\n",
            "Epoch 223/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.0306 - val_accuracy: 0.9933\n",
            "Epoch 224/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 0.0292 - val_accuracy: 0.9933\n",
            "Epoch 225/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.0431 - val_accuracy: 0.9867\n",
            "Epoch 226/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.0423 - val_accuracy: 0.9900\n",
            "Epoch 227/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.0296 - val_accuracy: 0.9917\n",
            "Epoch 228/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.0268 - val_accuracy: 0.9900\n",
            "Epoch 229/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.0386 - val_accuracy: 0.9900\n",
            "Epoch 230/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.0259 - val_accuracy: 0.9950\n",
            "Epoch 231/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0277 - val_accuracy: 0.9933\n",
            "Epoch 232/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.0265 - val_accuracy: 0.9933\n",
            "Epoch 233/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.0284 - val_accuracy: 0.9933\n",
            "Epoch 234/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.0298 - val_accuracy: 0.9917\n",
            "Epoch 235/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0290 - accuracy: 0.9897 - val_loss: 0.0448 - val_accuracy: 0.9867\n",
            "Epoch 236/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0257 - val_accuracy: 0.9933\n",
            "Epoch 237/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0173 - accuracy: 0.9933 - val_loss: 0.0402 - val_accuracy: 0.9883\n",
            "Epoch 238/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.0305 - val_accuracy: 0.9917\n",
            "Epoch 239/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0160 - accuracy: 0.9940 - val_loss: 0.0312 - val_accuracy: 0.9900\n",
            "Epoch 240/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0242 - val_accuracy: 0.9917\n",
            "Epoch 241/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.0293 - val_accuracy: 0.9917\n",
            "Epoch 242/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.0233 - val_accuracy: 0.9917\n",
            "Epoch 243/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0303 - val_accuracy: 0.9933\n",
            "Epoch 244/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.0251 - val_accuracy: 0.9900\n",
            "Epoch 245/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.0257 - val_accuracy: 0.9933\n",
            "Epoch 246/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 0.0415 - val_accuracy: 0.9867\n",
            "Epoch 247/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.0250 - val_accuracy: 0.9933\n",
            "Epoch 248/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0226 - val_accuracy: 0.9900\n",
            "Epoch 249/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0322 - val_accuracy: 0.9917\n",
            "Epoch 250/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0152 - accuracy: 0.9943 - val_loss: 0.0358 - val_accuracy: 0.9900\n",
            "Epoch 251/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.0296 - val_accuracy: 0.9917\n",
            "Epoch 252/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.0338 - val_accuracy: 0.9900\n",
            "Epoch 253/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0266 - val_accuracy: 0.9900\n",
            "Epoch 254/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0375 - val_accuracy: 0.9917\n",
            "Epoch 255/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.0411 - val_accuracy: 0.9900\n",
            "Epoch 256/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.0219 - val_accuracy: 0.9950\n",
            "Epoch 257/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0279 - val_accuracy: 0.9917\n",
            "Epoch 258/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.0243 - val_accuracy: 0.9933\n",
            "Epoch 259/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0269 - val_accuracy: 0.9967\n",
            "Epoch 260/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0285 - val_accuracy: 0.9933\n",
            "Epoch 261/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0231 - val_accuracy: 0.9950\n",
            "Epoch 262/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0146 - accuracy: 0.9940 - val_loss: 0.0243 - val_accuracy: 0.9967\n",
            "Epoch 263/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0330 - val_accuracy: 0.9900\n",
            "Epoch 264/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.0273 - val_accuracy: 0.9917\n",
            "Epoch 265/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0256 - val_accuracy: 0.9900\n",
            "Epoch 266/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0238 - val_accuracy: 0.9950\n",
            "Epoch 267/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0286 - val_accuracy: 0.9900\n",
            "Epoch 268/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0276 - val_accuracy: 0.9917\n",
            "Epoch 269/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0257 - val_accuracy: 0.9933\n",
            "Epoch 270/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.0252 - val_accuracy: 0.9950\n",
            "Epoch 271/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0230 - val_accuracy: 0.9933\n",
            "Epoch 272/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0267 - val_accuracy: 0.9950\n",
            "Epoch 273/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0184 - accuracy: 0.9927 - val_loss: 0.0347 - val_accuracy: 0.9917\n",
            "Epoch 274/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0218 - val_accuracy: 0.9950\n",
            "Epoch 275/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.0241 - val_accuracy: 0.9950\n",
            "Epoch 276/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0279 - val_accuracy: 0.9917\n",
            "Epoch 277/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.0250 - val_accuracy: 0.9950\n",
            "Epoch 278/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.0242 - val_accuracy: 0.9900\n",
            "Epoch 279/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0354 - val_accuracy: 0.9933\n",
            "Epoch 280/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0381 - val_accuracy: 0.9900\n",
            "Epoch 281/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0258 - val_accuracy: 0.9950\n",
            "Epoch 282/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0432 - val_accuracy: 0.9867\n",
            "Epoch 283/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.1436 - val_accuracy: 0.9583\n",
            "Epoch 284/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0541 - accuracy: 0.9840 - val_loss: 0.0230 - val_accuracy: 0.9950\n",
            "Epoch 285/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.0258 - val_accuracy: 0.9950\n",
            "Epoch 286/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.0257 - val_accuracy: 0.9950\n",
            "Epoch 287/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0304 - val_accuracy: 0.9933\n",
            "Epoch 288/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0147 - accuracy: 0.9943 - val_loss: 0.0284 - val_accuracy: 0.9933\n",
            "Epoch 289/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 0.0215 - val_accuracy: 0.9967\n",
            "Epoch 290/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0194 - val_accuracy: 0.9967\n",
            "Epoch 291/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.0442 - val_accuracy: 0.9867\n",
            "Epoch 292/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0231 - val_accuracy: 0.9967\n",
            "Epoch 293/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 0.0269 - val_accuracy: 0.9967\n",
            "Epoch 294/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0224 - val_accuracy: 0.9917\n",
            "Epoch 295/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0276 - val_accuracy: 0.9967\n",
            "Epoch 296/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0275 - val_accuracy: 0.9933\n",
            "Epoch 297/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.0257 - val_accuracy: 0.9950\n",
            "Epoch 298/300\n",
            "47/47 [==============================] - 7s 154ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0316 - val_accuracy: 0.9917\n",
            "Epoch 299/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.0216 - val_accuracy: 0.9933\n",
            "Epoch 300/300\n",
            "47/47 [==============================] - 7s 155ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.0263 - val_accuracy: 0.9933\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 1s 28ms/step - loss: 0.0325 - accuracy: 0.9900\n",
            "Test accuracy: 0.9900000095367432\n"
          ]
        }
      ],
      "source": [
        "telegram_reporter(\"Starting training\");\n",
        "\n",
        "cnn = CNNModel();\n",
        "model = cnn.fitting();\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "telegram_reporter(\"Training done\");\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}